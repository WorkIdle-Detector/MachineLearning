{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"ggpLxfhj_U6V"},"outputs":[],"source":["import sys\n","sys.path.append('deep_sort')\n","sys.path.append('pictor-ppe')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LBhsIL5TuS3T"},"outputs":[],"source":["import tensorflow as tf\n","import tensorflow.keras.backend as K\n","from tensorflow.keras.layers import Input\n","\n","import numpy as np\n","import pandas as pd\n","import cv2\n","\n","import matplotlib.pyplot as plt\n","import matplotlib as mpl\n","\n","from IPython.display import display, Math\n","from time import time\n","\n","# import sys\n","# sys.path.append('../')\n","\n","from src.utils.image import letterbox_image, draw_detection\n","from src.yolo3.model import yolo_body\n","\n","from src.utils.fixes import *\n","fix_tf_gpu()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BesDxGjcuS3T"},"outputs":[],"source":["class_names = ['H', 'V']\n","\n","# определяет три серии якорей для трех output-слоёв (слои для улучшения показателей обнаружения объектов разных масштабов)\n","# [w, h]\n","# отсортированы в порядке по высоте\n","# anchor_boxes = np.array(\n","#         [\n","#           np.array([[ 53, 198 ], [ 117, 294], [293, 334]]) /64, # output-1 anchor boxes (sizes of anchor boxes (relative to grid cell width and height))\n","#           np.array([[73, 63], [30, 97], [153, 119]]) /32, # output-2 anchor boxes\n","#           np.array([[8, 16], [38, 27], [19, 48]]) /16   # output-3 anchor boxes\n","#         ],\n","#         dtype='float64'\n","#     )\n","\n","anchor_boxes = np.array(\n","        [\n","          np.array([[153, 119], [ 117, 294], [293, 334]]) /32, # output-1 anchor boxes (sizes of anchor boxes (relative to grid cell width and height))\n","          np.array([[73, 63], [30, 97], [ 53, 198 ]]) /16, # output-2 anchor boxes\n","          np.array([[8, 16], [38, 27], [19, 48]]) /8   # output-3 anchor boxes\n","        ],\n","        dtype='float64'\n","    )\n","\n","input_shape  = (1248, 1248)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I_Xo_7K4uS3U"},"outputs":[],"source":["K.clear_session() # clear memory\n","\n","# number of classes and number of anchors\n","# num_classes = len(class_names)\n","num_classes = 3\n","num_anchors = anchor_boxes.shape[0] * anchor_boxes.shape[1]\n","\n","# input and output\n","input_tensor = Input( shape=(input_shape[0], input_shape[1], 3) ) # input\n","# num_out_filters = ( num_anchors//3 ) * ( 5 + num_classes )        # output\n","num_out_filters = 3 * ( 5 + num_classes )        # output\n","\n","\n","# build the model\n","model = yolo_body(input_tensor, num_out_filters)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LUZixKVMuS3U"},"outputs":[],"source":["weight_path = sys.path[-1] + 'path_to_model_weights'\n","\n","model.load_weights( weight_path )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EsR8C-HWuS3d"},"outputs":[],"source":["def detection(\n","    prediction,\n","    anchor_boxes,\n","    num_classes,\n","    image_shape,\n","    input_shape,\n","    max_boxes = 20,\n","    score_threshold=0.3,\n","    iou_threshold=0.45,\n","    classes_can_overlap=True,\n","):\n","    '''\n","    INPUT:\n","    OUTPUT:\n","    '''\n","\n","    all_boxes  = []\n","\n","    '''@ Each output layer'''\n","    for output, anchors in zip( prediction, anchor_boxes ):\n","\n","        '''Preprocessing'''\n","        '''-------------'''\n","        # shapes\n","        batch_size     = output.shape[0]\n","        grid_h, grid_w = output.shape[1:3]\n","\n","        # reshape to [batch_size, grid_height, grid_width, num_anchors, box_params]\n","        output = tf.reshape( output, [ -1, grid_h, grid_w, len(anchors), num_classes+5 ] )\n","\n","        # create a tensor for the anchor boxes\n","        anchors_tensor = tf.constant(anchors, dtype=output.dtype)\n","\n","        '''Scaling factors'''\n","        '''---------------'''\n","        image_shape_tensor = tf.cast( image_shape,       output.dtype ) # actual image's shape\n","        grids_shape_tensor = tf.cast( output.shape[1:3], output.dtype ) # grid_height, grid_width @ output layer\n","        input_shape_tensor = tf.cast( input_shape,       output.dtype )  # yolo input image's shape\n","\n","        # reshape\n","        image_shape_tensor = tf.reshape( image_shape_tensor, [-1, 1, 1, 1, 2] )\n","        grids_shape_tensor = tf.reshape( grids_shape_tensor, [-1, 1, 1, 1, 2] )\n","        input_shape_tensor = tf.reshape( input_shape_tensor, [-1, 1, 1, 1, 2] )\n","\n","        ### Scaling factors\n","        sized_shape_tensor = tf.round( image_shape_tensor * tf.reshape( tf.reduce_min( input_shape_tensor / image_shape_tensor, axis=-1 ), [-1,1,1,1,1] ) )\n","        # to scale the boxes from grid's unit to actual image's pixel unit\n","        box_scaling = input_shape_tensor * image_shape_tensor / sized_shape_tensor / grids_shape_tensor\n","        # to offset the boxes\n","        box_offsets = (tf.expand_dims(tf.reduce_max(image_shape_tensor, axis=-1), axis=-1) - image_shape_tensor) / 2.\n","\n","        '''Box geometric properties'''\n","        '''------------------------'''\n","        grid_h, grid_w = output.shape[1:3] # grid_height, grid_width @ output layer\n","\n","        grid_i = tf.reshape( np.arange(grid_h), [-1, 1, 1, 1] )\n","        grid_i = tf.tile( grid_i, [1, grid_w, 1, 1] )\n","\n","        grid_j = tf.reshape( np.arange(grid_w), [1, -1, 1, 1] )\n","        grid_j = tf.tile( grid_j, [grid_h, 1, 1, 1] )\n","\n","        grid_ji = tf.concat( [grid_j, grid_i], axis=-1 )\n","        grid_ji = tf.cast( grid_ji, output.dtype )\n","\n","        # Box centers\n","        box_xy  = output[..., 0:2]\n","        box_xy  = tf.sigmoid( box_xy ) + grid_ji\n","\n","        # Box sizes\n","        box_wh  = output[..., 2:4]\n","        box_wh  = tf.exp( box_wh ) * anchors_tensor\n","\n","        # scale to actual pixel unit\n","        box_xy  = box_xy * box_scaling - box_offsets[...,::-1]\n","        box_wh  = box_wh * box_scaling\n","\n","        # calculate top-left corner (x1, y1) and bottom-right corner (x2, y2) of the boxex\n","        box_x1_y1 = box_xy - box_wh / 2\n","        box_x2_y2 = box_xy + box_wh / 2\n","\n","        # top-left corner cannot be negative\n","        box_x1_y1 = tf.maximum(0, box_x1_y1)\n","        # bottom-right corner cannot be more than actual image size\n","        box_x2_y2 = tf.minimum(box_x2_y2, image_shape_tensor[..., ::-1])\n","\n","        '''Box labels and confidences'''\n","        '''--------------------------'''\n","        # class probabilities = objectness score * conditional class probabilities\n","        if classes_can_overlap:\n","            # use sigmoid for the conditional class probabilities\n","            classs_probs = tf.sigmoid( output[..., 4:5] ) * tf.sigmoid( output[..., 5:] )\n","        else:\n","            # use softmax for the conditional class probabilities\n","            classs_probs = tf.sigmoid( output[..., 4:5] ) * tf.nn.softmax( output[..., 5:] )\n","\n","        box_cl = tf.argmax( classs_probs, axis=-1 )     # final classes\n","        box_sc = tf.reduce_max( classs_probs, axis=-1 ) # confidence scores\n","\n","        '''Organize'''\n","        '''--------'''\n","        # take care of dtype and dimensions\n","        box_cl = tf.cast( box_cl, output.dtype )\n","        box_cl = tf.expand_dims(box_cl, axis=-1)\n","        box_sc = tf.expand_dims(box_sc, axis=-1)\n","\n","        # store all information as: [ left(x1), top(y1), right(x2), bottom(y2),  confidence, label ]\n","        boxes  = tf.reshape( tf.concat( [ box_x1_y1, box_x2_y2, box_sc, box_cl ], axis=-1 ),\n","                              [batch_size, -1, 6] )\n","\n","        all_boxes. append( boxes  )\n","\n","    # Merge across all output layers\n","    all_boxes  = tf.concat( all_boxes,  axis=1 )\n","\n","    # To store all the final results of all images in the batch\n","    all_final_boxes = []\n","\n","    '''For each image in the batch'''\n","    for _boxes_ in all_boxes:\n","\n","        if classes_can_overlap:\n","            '''Perform NMS for each class individually'''\n","\n","            # to stote the final results of this image\n","            final_boxes = []\n","\n","            # for class_id in range(num_classes):\n","            for class_id in [1]:\n","\n","                # Get the boxes and scores for this class\n","                class_boxes  = _boxes_[ _boxes_[...,-1] == class_id ]\n","\n","                '''Non-max-suppression'''\n","                selected_idc = tf.image.non_max_suppression(\n","                    class_boxes[...,:4], # boxes' (y1,x1,y2,x2)\n","                    class_boxes[...,-2], # boxes' scores\n","                    max_output_size = max_boxes,\n","                    iou_threshold = iou_threshold,\n","                    score_threshold = score_threshold\n","                )\n","\n","                # boxes selected by nms\n","                class_boxes = tf.gather( class_boxes,  selected_idc )\n","                final_boxes.append( class_boxes )\n","\n","            # concatenate boxes for each class in the image\n","            final_boxes  = tf.concat( final_boxes,  axis=0 )\n","\n","        else:\n","            '''Perform NMS for all classes'''\n","\n","            # nms indices\n","            selected_idc = tf.image.non_max_suppression(\n","                _boxes_[...,:4], # boxes' (y1,x1,y2,x2)\n","                _boxes_[...,-2], # boxes' scores\n","                max_output_size = max_boxes,\n","                iou_threshold = iou_threshold,\n","                score_threshold = score_threshold\n","            )\n","\n","            # boxes selected by nms\n","            final_boxes = tf.gather( _boxes_,  selected_idc )\n","\n","        # append final boxes for each image in the batch\n","        all_final_boxes.append( final_boxes )\n","\n","    return all_final_boxes"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":274800,"status":"ok","timestamp":1687571242543,"user":{"displayName":"Владимир Сторожилов","userId":"07368996924489228691"},"user_tz":-180},"id":"hMpEbh7D2hlX","outputId":"e20c0834-be8a-42b9-c15f-2b2eec56487c"},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 229ms/step\n","1/1 [==============================] - 0s 217ms/step\n","1/1 [==============================] - 0s 228ms/step\n","1/1 [==============================] - 0s 203ms/step\n","1/1 [==============================] - 0s 201ms/step\n","1/1 [==============================] - 0s 200ms/step\n","1/1 [==============================] - 0s 214ms/step\n","1/1 [==============================] - 0s 214ms/step\n","1/1 [==============================] - 0s 210ms/step\n","1/1 [==============================] - 0s 207ms/step\n","1/1 [==============================] - 0s 209ms/step\n","1/1 [==============================] - 0s 201ms/step\n","1/1 [==============================] - 0s 202ms/step\n","1/1 [==============================] - 0s 199ms/step\n","1/1 [==============================] - 0s 206ms/step\n","1/1 [==============================] - 0s 200ms/step\n","1/1 [==============================] - 0s 198ms/step\n","1/1 [==============================] - 0s 200ms/step\n","1/1 [==============================] - 0s 209ms/step\n","1/1 [==============================] - 0s 200ms/step\n","1/1 [==============================] - 0s 202ms/step\n","1/1 [==============================] - 0s 198ms/step\n","1/1 [==============================] - 0s 206ms/step\n","1/1 [==============================] - 0s 200ms/step\n","1/1 [==============================] - 0s 201ms/step\n","1/1 [==============================] - 0s 204ms/step\n","1/1 [==============================] - 0s 207ms/step\n","1/1 [==============================] - 0s 209ms/step\n","1/1 [==============================] - 0s 202ms/step\n","1/1 [==============================] - 0s 203ms/step\n","1/1 [==============================] - 0s 205ms/step\n","1/1 [==============================] - 0s 206ms/step\n","1/1 [==============================] - 0s 202ms/step\n","1/1 [==============================] - 0s 204ms/step\n","1/1 [==============================] - 0s 202ms/step\n","1/1 [==============================] - 0s 204ms/step\n","1/1 [==============================] - 0s 204ms/step\n","1/1 [==============================] - 0s 206ms/step\n","1/1 [==============================] - 0s 211ms/step\n","1/1 [==============================] - 0s 203ms/step\n","1/1 [==============================] - 0s 204ms/step\n","1/1 [==============================] - 0s 204ms/step\n","1/1 [==============================] - 0s 204ms/step\n","1/1 [==============================] - 0s 221ms/step\n","1/1 [==============================] - 0s 218ms/step\n","1/1 [==============================] - 0s 205ms/step\n","1/1 [==============================] - 0s 200ms/step\n","1/1 [==============================] - 0s 204ms/step\n","1/1 [==============================] - 0s 204ms/step\n","1/1 [==============================] - 0s 202ms/step\n","1/1 [==============================] - 0s 204ms/step\n","1/1 [==============================] - 0s 203ms/step\n","1/1 [==============================] - 0s 209ms/step\n","1/1 [==============================] - 0s 220ms/step\n","1/1 [==============================] - 0s 203ms/step\n","1/1 [==============================] - 0s 202ms/step\n","1/1 [==============================] - 0s 206ms/step\n","1/1 [==============================] - 0s 204ms/step\n","1/1 [==============================] - 0s 200ms/step\n","1/1 [==============================] - 0s 206ms/step\n","1/1 [==============================] - 0s 203ms/step\n","1/1 [==============================] - 0s 199ms/step\n","1/1 [==============================] - 0s 207ms/step\n","1/1 [==============================] - 0s 201ms/step\n","1/1 [==============================] - 0s 200ms/step\n","1/1 [==============================] - 0s 201ms/step\n","1/1 [==============================] - 0s 202ms/step\n","1/1 [==============================] - 0s 202ms/step\n","1/1 [==============================] - 0s 205ms/step\n","1/1 [==============================] - 0s 207ms/step\n","1/1 [==============================] - 0s 210ms/step\n","1/1 [==============================] - 0s 204ms/step\n","1/1 [==============================] - 0s 202ms/step\n","1/1 [==============================] - 0s 201ms/step\n","1/1 [==============================] - 0s 207ms/step\n","1/1 [==============================] - 0s 207ms/step\n","1/1 [==============================] - 0s 206ms/step\n","1/1 [==============================] - 0s 203ms/step\n","1/1 [==============================] - 0s 201ms/step\n","1/1 [==============================] - 0s 215ms/step\n","1/1 [==============================] - 0s 204ms/step\n","1/1 [==============================] - 0s 200ms/step\n","1/1 [==============================] - 0s 206ms/step\n","1/1 [==============================] - 0s 204ms/step\n","1/1 [==============================] - 0s 202ms/step\n","1/1 [==============================] - 0s 202ms/step\n","1/1 [==============================] - 0s 201ms/step\n","1/1 [==============================] - 0s 206ms/step\n","1/1 [==============================] - 0s 202ms/step\n","1/1 [==============================] - 0s 206ms/step\n","1/1 [==============================] - 0s 204ms/step\n","1/1 [==============================] - 0s 203ms/step\n","1/1 [==============================] - 0s 205ms/step\n","1/1 [==============================] - 0s 201ms/step\n","1/1 [==============================] - 0s 198ms/step\n","1/1 [==============================] - 0s 203ms/step\n","1/1 [==============================] - 0s 207ms/step\n","1/1 [==============================] - 0s 203ms/step\n","1/1 [==============================] - 0s 206ms/step\n","1/1 [==============================] - 0s 202ms/step\n","1/1 [==============================] - 0s 205ms/step\n","1/1 [==============================] - 0s 201ms/step\n","1/1 [==============================] - 0s 200ms/step\n","1/1 [==============================] - 0s 210ms/step\n","1/1 [==============================] - 0s 207ms/step\n","1/1 [==============================] - 0s 203ms/step\n","1/1 [==============================] - 0s 202ms/step\n","1/1 [==============================] - 0s 202ms/step\n","1/1 [==============================] - 0s 202ms/step\n","1/1 [==============================] - 0s 200ms/step\n","1/1 [==============================] - 0s 209ms/step\n","1/1 [==============================] - 0s 206ms/step\n","1/1 [==============================] - 0s 201ms/step\n","1/1 [==============================] - 0s 210ms/step\n","1/1 [==============================] - 0s 204ms/step\n","1/1 [==============================] - 0s 202ms/step\n","1/1 [==============================] - 0s 200ms/step\n","1/1 [==============================] - 0s 207ms/step\n","1/1 [==============================] - 0s 202ms/step\n","1/1 [==============================] - 0s 198ms/step\n","1/1 [==============================] - 0s 201ms/step\n","1/1 [==============================] - 0s 204ms/step\n","1/1 [==============================] - 0s 202ms/step\n","1/1 [==============================] - 0s 207ms/step\n","1/1 [==============================] - 0s 217ms/step\n","1/1 [==============================] - 0s 207ms/step\n","1/1 [==============================] - 0s 203ms/step\n","1/1 [==============================] - 0s 200ms/step\n","1/1 [==============================] - 0s 208ms/step\n","1/1 [==============================] - 0s 203ms/step\n","1/1 [==============================] - 0s 201ms/step\n","1/1 [==============================] - 0s 203ms/step\n","1/1 [==============================] - 0s 204ms/step\n","1/1 [==============================] - 0s 204ms/step\n","1/1 [==============================] - 0s 200ms/step\n","1/1 [==============================] - 0s 203ms/step\n","1/1 [==============================] - 0s 203ms/step\n","1/1 [==============================] - 0s 203ms/step\n","1/1 [==============================] - 0s 203ms/step\n","1/1 [==============================] - 0s 204ms/step\n","1/1 [==============================] - 0s 207ms/step\n","1/1 [==============================] - 0s 206ms/step\n","1/1 [==============================] - 0s 203ms/step\n","1/1 [==============================] - 0s 203ms/step\n","1/1 [==============================] - 0s 205ms/step\n","1/1 [==============================] - 0s 204ms/step\n","1/1 [==============================] - 0s 212ms/step\n","1/1 [==============================] - 0s 210ms/step\n","1/1 [==============================] - 0s 202ms/step\n","1/1 [==============================] - 0s 203ms/step\n","1/1 [==============================] - 0s 202ms/step\n","1/1 [==============================] - 0s 201ms/step\n","1/1 [==============================] - 0s 202ms/step\n","1/1 [==============================] - 0s 207ms/step\n","1/1 [==============================] - 0s 206ms/step\n","1/1 [==============================] - 0s 201ms/step\n","1/1 [==============================] - 0s 202ms/step\n","time taken to process : 272722.66 ms\n"]}],"source":["import cv2\n","import numpy as np\n","# from deep_sort_realtime.deepsort_tracker import DeepSort\n","\n","# DeepSORT -> Importing DeepSORT.\n","from application_util import preprocessing\n","from deep_sort import nn_matching\n","from deep_sort.detection import Detection\n","from deep_sort.tracker import Tracker\n","from tools import generate_detections as gdet\n","\n","\n","video_frames = [];\n","\n","cap = cv2.VideoCapture(sys.path[-1] + '/../ConstructionSiteOne.mp4')\n","fps = cap.get(cv2.CAP_PROP_FPS)\n","\n","frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))   # float `width`\n","frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))  # float `height`\n","\n","out = cv2.VideoWriter(\n","    sys.path[-1] + '/../outputOne.mp4',\n","    cv2.VideoWriter_fourcc(*'MP4V'),\n","    fps,\n","     (frame_width, frame_height)\n",")\n","\n","model_filename = sys.path[-1] + '/../mars-small128.pb'\n","encoder = gdet.create_box_encoder(model_filename, batch_size=1)\n","\n","max_cosine_distance = 0.4\n","nn_budget = 100\n","metric = nn_matching.NearestNeighborDistanceMetric(\"cosine\", max_cosine_distance, nn_budget)\n","# nn_matching.\n","tracker = Tracker(\n","    metric,\n","    max_iou_distance=0.7,\n","    max_age = int(10 * fps)\n",")\n","\n","# tracker = DeepSort(\n","#     max_age=int(fps * 10),\n","#     max_cosine_distance=0.2,\n","#     embedder='mobilenet',\n","# )\n","\n","# Check if camera opened successfully\n","if (cap.isOpened()== False):\n","  print(\"Error opening video stream or file\")\n","\n","# Save original image shape\n","image_shape = np.array( [frame_height, frame_width] )\n","\n","counter = 1\n","batch_frames = []\n","batch_frames_resized = []\n","diff_frames = [np.zeros(shape=image_shape)]\n","\n","'''Get the boxes'''\n","t0 = time() # set a timer\n","ress = []\n","tracks_arr = []\n","\n","prev_frame = None\n","\n","while(cap.isOpened()):\n","  ret, frame = cap.read()\n","  if ret == True:\n","    batch_frames.append(frame)\n","    batch_frames_resized.append(letterbox_image(frame, (1248, 1248))/255.)\n","\n","    # Smoothing (to delete unnecessory noise) and grayscayling\n","    blured_frame  = cv2.GaussianBlur(frame, (5,5), 0)\n","    buff_frame = cv2.cvtColor(blured_frame, cv2.COLOR_BGR2GRAY)\n","    if counter > 1:\n","      diff_frame = abs(buff_frame - prev_frame)\n","      diff_frames.append(diff_frame)\n","    prev_frame = buff_frame\n","\n","    if counter % 10 == 0:\n","      image_data  = np.array( batch_frames_resized )\n","\n","      prediction = model.predict(image_data)\n","\n","      boxes = detection(\n","          prediction,\n","          anchor_boxes,\n","          num_classes,\n","          image_shape,\n","          input_shape = (1248, 1248),\n","          max_boxes = 10,\n","          score_threshold=0.5,\n","          iou_threshold=0.45)\n","\n","      dets = [[[[box[0],  box[1], box[2] - box[0], box[3] - box[1]], box[4]]\n","      for box in image_boxes.numpy()]\n","      for image_boxes in boxes]\n","\n","      # detections = [[([int(box[0]),  int(box[1]), int(box[2] - box[0]), int(box[3] - box[1])], box[4], box[5])\n","      # for box in image_boxes.numpy()]\n","      # for image_boxes in boxes]\n","\n","      for detection_batch, fframe, bboxes, dif_frame in zip(dets, batch_frames, boxes, diff_frames):\n","        detts = [x[0] for x in detection_batch]\n","        scores = [x[1] for x in detection_batch]\n","        features = encoder(fframe, detts)\n","        # features = np.ones(shape=(len(detection_batch), 128), dtype='float64')\n","        detections = [Detection(bbox, score, feature) for bbox, score, feature in zip(detts, scores, features)]\n","        tracker.predict()\n","        tracker.update(detections)\n","        tracks = tracker.tracks\n","        res_img = draw_detection(fframe, tracks, class_names, dif_frame)\n","        out.write(res_img)\n","\n","      # for detection_batch, fframe, bboxes in zip(detections, batch_frames, boxes):\n","      #   tracks = tracker.update_tracks(detection_batch, frame=fframe, embeds=[[1, 1, 1] for x in detection_batch])\n","      #   res_img = draw_detection(fframe, bboxes.numpy(), tracks, class_names)\n","      #   out.write(res_img)\n","      #   tracks_arr.append([[x for x in track.mean] for track in tracks])\n","\n","      batch_frames.clear()\n","      batch_frames_resized.clear()\n","      diff_frames.clear()\n","\n","      if counter == 11:\n","        break\n","\n","    counter += 1\n","\n","  else:\n","    break\n","\n","cap.release()\n","out.release()\n","\n","print('time taken to process : {:.2f} ms'.format( (time()-t0)*1000 ))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":39714,"status":"ok","timestamp":1687572101203,"user":{"displayName":"Владимир Сторожилов","userId":"07368996924489228691"},"user_tz":-180},"id":"bw_qT1tVsS31","outputId":"86e5853a-4461-4f4b-844e-21a15fcff565"},"outputs":[{"name":"stdout","output_type":"stream","text":["time taken to process : 38991.49 ms\n"]}],"source":["import cv2\n","import numpy as np\n","# from deep_sort_realtime.deepsort_tracker import DeepSort\n","\n","# DeepSORT -> Importing DeepSORT.\n","from application_util import preprocessing\n","from deep_sort import nn_matching\n","from deep_sort.detection import Detection\n","from deep_sort.tracker import Tracker\n","from tools import generate_detections as gdet\n","\n","\n","video_frames = [];\n","\n","cap = cv2.VideoCapture(sys.path[-1] + 'path_to_input_video')\n","fps = cap.get(cv2.CAP_PROP_FPS)\n","\n","frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))   # float `width`\n","frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))  # float `height`\n","\n","out = cv2.VideoWriter(\n","    sys.path[-1] + 'path_to_output_video',\n","    cv2.VideoWriter_fourcc(*'MP4V'),\n","    fps,\n","     (frame_width, frame_height)\n",")\n","\n","\n","# Check if camera opened successfully\n","if (cap.isOpened()== False):\n","  print(\"Error opening video stream or file\")\n","\n","# Save original image shape\n","image_shape = np.array( [frame_height, frame_width] )\n","\n","counter = 1\n","diff_frame = np.zeros(shape=(720, 1280), dtype='uint8')\n","\n","'''Get the boxes'''\n","t0 = time() # set a timer\n","\n","prev_frame = None\n","\n","while(cap.isOpened()):\n","  ret, frame = cap.read()\n","  if ret == True:\n","    frame  = cv2.GaussianBlur(frame, (9,9), 5)\n","    buff_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n","    if counter > 1:\n","      diff_frame = abs(buff_frame - prev_frame).astype('uint8')\n","      diff_frame[diff_frame < 200] = 0\n","    prev_frame = buff_frame\n","    out.write(np.repeat(np.expand_dims(diff_frame, axis=-1), 3, axis=-1))\n","    counter += 1\n","    # print('Writed')\n","  else:\n","    break\n","\n","cap.release()\n","out.release()\n","\n","print('time taken to process : {:.2f} ms'.format( (time()-t0)*1000 ))\n"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMcrBTgJe3YX8P4a6+LlaQn","gpuType":"T4","machine_shape":"hm","mount_file_id":"1myroEk9g7kLZHu1VN94hYRuj2bTmhY5o","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
